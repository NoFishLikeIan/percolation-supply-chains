\documentclass[american, abstract=on]{scrartcl}

    \newcommand{\lang}{en}

    \usepackage{babel}
    \usepackage[utf8]{inputenc}

    \usepackage{csquotes}

    \usepackage{amsmath, amssymb, mathtools, bbm}
    \usepackage{amsthm}
    \usepackage{xcolor}
    \usepackage{xcolor-solarized}
    \usepackage{bm}

    \usepackage{graphicx}
    \usepackage{wrapfig}
    \usepackage{relsize}
    \usepackage{makecell}
    \usepackage{booktabs}
    \usepackage[font=footnotesize,labelfont=bf]{caption}
    \usepackage{subcaption}
    \usepackage{float}
    \usepackage{multirow} 
    \usepackage{hyperref}
    
    % Formatting
    \setlength{\parindent}{0em}
    \setlength{\parskip}{0.5em}
    \setlength{\fboxsep}{1em}
    \newcommand\headercell[1]{\smash[b]{\begin{tabular}[t]{@{}c@{}} #1 \end{tabular}}}

    % Theorems
    \theoremstyle{plain}
    \newtheorem{claim}{Claim}

    % Math commands

    \newcommand{\diff}{\text{d}}
    \renewcommand{\Re}{\mathbb{R}}
    \newcommand{\C}{\mathcal{C}}
    \newcommand{\F}{\mathcal{F}}
    \newcommand{\X}{\mathcal{X}}
    \newcommand{\G}{\mathcal{G}}
    \newcommand{\I}{\mathcal{I}}
    \newcommand{\N}{\mathcal{N}}
    \newcommand{\PF}{\mathcal{P} \F}

    \renewcommand{\P}{\mathbb{P}}
    \newcommand{\E}{\mathbb{E}}
    \newcommand{\V}{\mathbb{V}}

    \newcommand{\uI}[2][s]{\int^1_0 #2 \ \text{d} #1}
    \newcommand{\uH}[2][s]{\int^\frac{1}{2}_0 #2 \ \text{d} #1}
    \newcommand{\uF}[2][s]{\int^1_\frac{1}{2} #2 \ \text{d} #1}
    \newcommand{\norm}[1]{\left\lVert#1\right\rVert}
    \newcommand{\abs}[1]{\left\lvert#1\right\rvert}

    \newcommand{\Beta}{\text{Beta}}
    \newcommand{\Bin}{\text{Bin}}

    \DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

    % Bibliography

    \usepackage[bibencoding=utf8, style=apa, backend=biber]{biblatex}
    \addbibresource{../supply-chain-reallocation.bib}
    \addbibresource{../math.bib}

    \newcommand{\citein}[1]{\citeauthor{#1} (\citeyear{#1})}

    % Make title page

    \author{Andrea Titton}
    \title{Derivation of mapping}

    \setcounter{section}{-1}  % Start numbering at 0
    
\begin{document}

\maketitle

\section{Notation}

\begin{enumerate}
    \item For some integer $m$, let $[m] \coloneqq \{0, 1, \ldots, m\}$.
    \item For two numbers $x, s$ let the falling factorial of $x$ to $s$ be \begin{equation}
        (x)_s \coloneqq \begin{cases} x(x - 1)(x - 2)\ldots(x - (s - 1)) & \text{if } s \in \mathbb{N}_0 \\
       \Gamma(1 + x) \Big/ \Gamma(1 + x - s)& \text{if } s \in \Re^{+}
        \end{cases}
    \end{equation} and the rising factorial of $x$ to $s$ be \begin{equation}
        x^{(s)} \coloneqq \begin{cases} x(x + 1)(x + 2)\ldots(x + (s - 1)) & \text{if } s \in \mathbb{N}_0 \\
            \Gamma(1 + x + s) \Big/ \Gamma(1 + x)& \text{if } s \in \Re^{+}
             \end{cases}
    \end{equation}. This notation is a bit contentious.
\end{enumerate}

\section{Problem statement}

Define $F \in [m]$ to be the number of functioning firm in the suppliers layer and assume 

\begin{equation}
    F \sim \Beta\Bin(m, f, \rho)
\end{equation}

with $m \in \mathbb{N}_0$ and $f, \rho \in [0, 1]$.

\subsection{Notes on the beta-binomial distribution}

\begin{enumerate}
    \item Usually, the beta-binomial is parametrized with two parameters $\alpha$ and $\beta$. Here I choose $f$ and $\rho$ instead, which provide a better interpretation for the problem at hand. The two parametrizations can be linked by taking \begin{equation}
        \rho = \frac{1}{\alpha + \beta + 1} \text{ and } f = \frac{\alpha}{\alpha + \beta}.
    \end{equation}
    \item The beta-binomial can be seen as a compounded random variable, generated by taking a binomial distribution $F \sim \Bin(m, p)$ with probability of success $p \sim \Beta(\alpha, \beta)$.
    \item The first two moments of the beta-binomial distribution can be written as \begin{equation}
        \E[F] = m f \text{ and } \V[F] = m f (1 - f) (1 + (m - 1) \rho).
    \end{equation} If $\rho = 0$, the beta-binomial degenerates into a binomial distribution, hence $\rho$ can be interpreted as an ``overdispersion'' vis-Ã -vis the binomial distribution.
    \item The probability mass function of the beta-binomial distribution is \begin{equation} \label{eq:pmf_betabinomial}
        f_F(k) = \binom{m}{k} \frac{B(k + \alpha, m - k + \beta)}{B(\alpha, \beta)}
    \end{equation} where $B$ is the beta function. 
    \item The moment generating function of the beta-binomial is \begin{equation} \label{eq:mgf_betabinomial}
        M_F(t) = \E\left[ e^{tF} \right] = \prescript{}{2}{F}_1(-m, \alpha, \alpha + \beta; 1 - e^{t}) = \sum^m_{n = 0} (-1)^n \binom{m}{n} \frac{B(\alpha + n, \beta)}{B(\alpha, \beta)} (1 - e^t)
    \end{equation}
\end{enumerate}

\subsection{The next layer probability}

Let $p$ be the function that maps the number of functioning firms in the suppliers layer and the number of chosen suppliers to the probability of a firm being functional in a given layer. In particular, $p: [0, m] \times \{0, 1, 2, \ldots m\} \to [0, 1]$ can be written equivalently

\begin{equation}
    p(s, F) = 1 - \binom{m - s}{F} \binom{m}{F}^{-1} = 1 - \frac{(m - F)_s}{(m)_s}
\end{equation}

Hereafter I will fit, by moments matching,

\begin{equation}
    p(s, F) \ \dot{\sim} \ \Beta(f', \rho').
\end{equation}

Motivated by simulated results (see \ref{fig:pfit}), I believe this to be not an approximation but the true distribution of $p(s, F)$. 

\begin{figure}[H]
    \centering
    \includegraphics[width = 0.8\linewidth]{../plots/pfit.png}
    \caption{Cumulative density function of $p(s, F)$ (line) and the fitted $\Beta$ distribution (scatter).}
    \label{fig:pfit}
\end{figure}

We parametrised $p(s, F)$ with $(f', \rho')$, which have the same interpretation as in $F$. In particular,

\begin{equation}
    \E\big[p(s, F)\big] = f' \text{ and } \V\big[p(s, F)\big] = f' (1 - f')\rho'.
\end{equation}

Again, if $\rho' = 0$, then $p(s, F) = f'$.

\section{Mapping between $F$ and $F'$}

Given that the probability of failure in the next layer is $p(s, F) \sim \Beta(f', \rho')$, the distribution of functioning firms 

\begin{equation}
    F' \sim \Bin(m, p(s, F)) \equiv \Beta\Bin(m, f', \rho').
\end{equation}

This formulation allows as to write, through $p(s, F)$, the mapping between the parameters of $F$ and $F'$

\begin{equation}
    \begin{pmatrix}
        f' \\ \rho'
    \end{pmatrix} =: \begin{pmatrix}
        G_f(f, \rho, s) \\ G_\rho(f, \rho, s)
    \end{pmatrix} =: G(f, \rho, s).
\end{equation}

\subsection{The mapping of the mean, $G_f$}

We can derive analytically the mapping $f' = G_f(f, \rho, s)$. In particular

\begin{equation}
    f' = \E\big[p(s, F)\big] = 1 - \frac{\E\big[(m - F)_s\big]}{(m)_s}.
\end{equation}

Notice that $F \sim \Beta\Bin(m, f, \rho)$ implies \begin{equation}(m - F) \sim \Beta\Bin(m, 1 - f, \rho).\end{equation}

Then $\E\big[(m - F)_s\big]$ is the factorial moment of a beta-binomial distribution that has a known analytical form

\begin{equation}
    \E\big[(m - F)_s\big] = (m)_s \frac{B\Big( (1 - f) \frac{1 - \rho}{\rho} + s, f \frac{1 - \rho}{\rho} \Big)}{B\Big( (1 - f) \frac{1 - \rho}{\rho}, f \frac{1 - \rho}{\rho} \Big)}
\end{equation}

such that

\begin{equation}
    G_f(f, \rho, s) = 1 - \frac{B\Big( (1 - f) \frac{1 - \rho}{\rho} + s, f \frac{1 - \rho}{\rho} \Big)}{B\Big( (1 - f) \frac{1 - \rho}{\rho}, f \frac{1 - \rho}{\rho} \Big)}.
\end{equation}

where $B(x, y)$ is the beta function.

\begin{figure}[H]
    \centering
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=\linewidth]{../plots/gf_small.pdf} 
      \caption{With $s = 1$}
      \label{fig:gf:small}  
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=\linewidth]{../plots/gf_large.pdf}       
      \caption{With $s = 20$}
      \label{fig:gf:large}
    \end{subfigure}
    \caption{Contour plot of $G_f - f$}
    \label{fig:gf}
  \end{figure}

Again, by rewriting

\begin{equation}
    G_f(f, \rho, s) = 1 - \frac{\Big( (1-f) \frac{1 - \rho}{\rho} \Big)_s}{\Big( \frac{1 - \rho}{\rho} \Big)_s} = 1 - \frac{(1 - f)^s \left(\frac{1 - \rho}{\rho}\right)^s + o\left(\left(\frac{1 - \rho}{\rho}\right)^{s - 1} \right) }{\left(\frac{1 - \rho}{\rho}\right)^s + o\left(\left(\frac{1 - \rho}{\rho}\right)^{s - 1} \right)}
\end{equation}

we can see that

\begin{equation}
    \lim_{\rho \rightarrow 0} G_f(f, \rho, s) = 1 - (1 - f)^s
\end{equation}

which is the limit case we expect if there is no correlation among suppliers and, hence, $F$ follows a binomial distribution.

\subsection{The mapping of overdispersion, $G_\rho$}

Unfortunately, we are not as lucky with the mapping for $\rho' = G_{\rho}(f, \rho, s)$. The first link we can make is using the definition of $\V[p(s, F)]$ to see that

\begin{equation}
    \rho' = \frac{\V[p(s, F)]}{f' \ (1 - f')}.
\end{equation}

where

\begin{equation}
    \V[p(s, F)] = \E[p(s, F)^2] - \underbrace{\E[p(s, F)]^2}_{\left(f'\right)^2}.
\end{equation}

Using the definition of $p$ we can write

\begin{equation}
    \begin{split}
        \E\big[ p(s, F)^2 \big] &= \E\left[1 - 2 \frac{(m - F)_s}{(m)_s} + \left(\frac{(m - F)_s}{(m)_s}  \right)^2\right] \\
        &= 1 - 2(1 - f') + \E\left[ \left(\frac{(m - F)_s}{(m)_s}  \right)^2 \right].
    \end{split}
\end{equation}

\iffalse
\subsubsection{Taylor series approach}

Let 

\begin{equation}
    \varphi_s(v) \coloneqq (m - v)^2_s.
\end{equation}

such that

\begin{equation}
    \E\big[ p(s, F)^2 \big] = 1 - 2(1 - f') + \E\left[ \frac{\varphi_s(F)}{\varphi_s(0)} \right].
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{../plots/phiplot.pdf} 
    \caption{A plot of $\varphi_s(v) / \varphi_s(0) = (m-v)^2_s / (m)^2_s$}
    \label{fig:phi}    
\end{figure}

Letting

\begin{equation}
    \Delta \psi^{(n)}_s(v) = \psi^{(n)}(1 + m - v) - \psi^{(n)}(1 + m - v - s)
\end{equation}

and noting that

\begin{equation}
    \frac{\text{d}}{\text{d}v} \Delta \psi^{(n)}_s(v) = -\Delta \psi^{(n + 1)}_s(v)
\end{equation}

we can write a recursive relationship for the derivatives of $\varphi_s(v)$

\begin{equation}
    \varphi_s^{(n)}(v) = (-1)^n a_{n}(v) \ \varphi_s(v)
\end{equation}

where

\begin{equation}
    a_{n+1} = \frac{\text{d}a_n}{\text{d}v} + 2 \Delta \psi^{(n)}_s \ a_n \text{ with } a_{0} = 1.
\end{equation}  

A Taylor expansion of $\varphi_s$ around $0$ allows us to write

\begin{equation}
    \E\left[\frac{\varphi_s(F)}{\varphi_s(0)}\right] = 1 + \sum^{\infty}_{n = 0} (-1)^n a_{n}(0) \frac{\E[F^n]}{n!}
\end{equation}
\fi

\subsubsection[Solution for m sufficiently large]{Solution for $m$ sufficiently large}

Let $R_m = F / m$. Then we can write $p$ as

\begin{equation}
    p(s, R_m) = 1 - \frac{(m(1- R_m))_s}{(m)_s}
\end{equation}

such that

\begin{equation}
   \E \left[p(s, R_m)^2\right] = 1 - 2(1 - f') + \E\left[\left(\frac{(m(1- R_m))_s}{(m)_s} \right)^2\right].
\end{equation}

Consider the last term

\begin{equation}
    \begin{split}
        \E\left[\left(\frac{(m(1- R_m))_s}{(m)_s} \right)^2\right] &= \E\left[ \frac{m^2 (1 - R_m)^2 (m (1 - R_m) - 1)^2 \ldots (m(1-R_m) - s + 1)^2}{m^2 (m - 1)^2 \ldots (m - s + 1)^2} \right] \\
        &= \E\left[\frac{m^{2s}(1- R_m)^{2s} + o(m^{2s - 1})}{m^{2s} + o(m^{2s - 1})}\right] \xrightarrow{m \rightarrow \infty} \E\Big[ (1 - R)^{2s} \Big]
    \end{split}
\end{equation}

where $R = \lim_{m \rightarrow \infty} R_m$. We can now look at the distribution of $R$. I will make a claim motivated by a simulation (see Figure \ref{fig:rdist}).


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{../plots/rlimit.pdf} 
    \caption{Simulated c.d.f. of $r$ and $\Bin$ with same parameters at $F$.}
    \label{fig:rdist}    
\end{figure}

\begin{claim}
    If $F \sim \Beta\Bin(m, \alpha, \beta)$ then $\lim_{m \rightarrow \infty} F / m \eqqcolon R \sim \Beta(\alpha, \beta)$.
\end{claim}

\begin{proof}

    The idea of the proof is to show that the moment generating function of $R_m$ converges pointwise to that of a beta distribution. This implies that the sequence $R_m$ converges in distribution to a beta, since the latter is determined by its moments (Theorem 30.2 in \citein{billingsley_probability_1995}). The moment generating function of $R_m$ can be written in terms of that of $F$ (\ref{eq:mgf_betabinomial}) as 

    \begin{equation}
        \begin{split}
            M_{R_m}(t) &= \E\left[e^{t R_m}\right] \\ 
            &= \E\left[e^{(t / m) F}\right] = M_F(t / m) \\
            &= \prescript{}{2}{F}_1(-m, \alpha, \alpha + \beta; 1 - e^{t / m}) \\
            &= \sum^m_{n = 0} (-1)^n \binom{m}{n} \frac{B(\alpha + n, \beta)}{B(\alpha, \beta)} (1 - e^{t / m}).
        \end{split}
    \end{equation}

    We seek to prove that this converges pointwise to 

    \begin{equation}
        M_R(t) = \prescript{}{1}{F}_1(\alpha, \alpha + \beta, t)= \sum^{\infty}_{n = 0} \frac{B(\alpha + n, \beta)}{B(\alpha, \beta)} \frac{t^n}{n!}.
    \end{equation}

    
    \textbf{To do...}\footnote{Unclear how to continue but a useful fact could be $\prescript{}{1}{F}_1(a; c; z) = \lim_{b \rightarrow \infty} \prescript{}{2}{F}_1(a, b; c; z / b)$}

\end{proof}

Given $R \sim \Beta(\alpha, \beta)$, such that $(1 - R) \sim \Beta(\beta, \alpha)$, we can write the $2s$-th moment of $1 - R$ as 

\begin{equation}
    \E[(1 - R)^{2s}] =  \left.\frac{\text{d}^{2s} M_{1 - R}}{\text{d}t^{2s}}\right\rvert_{t = 0} 
\end{equation}

hence, for large $m$,

\begin{equation}
    \begin{split}
        \E \left[p(s, R_m)^2\right] &\eqsim 1 - 2(1 - f') + \left.\frac{\text{d}^{2s} \prescript{}{1}{F}_1}{\text{d}t^{2s}} \right\rvert_{(\beta, \alpha + \beta, 0)} \\
        &= 1 - 2(1 - f') + \frac{\beta(\beta + 1)\ldots(\beta + 2s - 1)}{(\alpha + \beta)(\alpha + \beta + 1) \ldots (\alpha + \beta + 2s - 1)} \\
        \text{re-parametrising, } &= 1 - 2(1 - f') + \prod^{2s - 1}_{k = 0} \frac{f \frac{1 - \rho}{\rho} + k}{\frac{1 - \rho}{\rho} + k} \\
        &= 1 - 2(1 - f') + B\left(\frac{1 - \rho}{\rho}, 2s \right) \Big/ B\left((1 - f) \ \frac{1 - \rho}{\rho}, 2s \right)
    \end{split}
\end{equation}

where we have used $\frac{\text{d}}{\text{d}t} \prescript{}{1}{F}_1(a; b; t) = \frac{a}{b} \prescript{}{1}{F}_1(a + 1; b + 1; t)$ and $\prescript{}{1}{F}_1(\cdot, \cdot, 0) = 1$.

Hence, for large $m$, we can write our mapping $G_{\rho}$, letting $f' = G_f(f, \rho, s)$


\begin{equation}
    G_{\rho}(f, \rho, s) = \frac{ B\left(\frac{1 - \rho}{\rho}, 2s \right) \Big/ B\left((1 - f) \frac{1 - \rho}{\rho}, 2s \right)}{f' (1 - f')} - \frac{1 - f'}{f'}
\end{equation}


\begin{figure}[H]
    \centering
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=\linewidth]{../plots/grho_small.pdf} 
      \caption{With $s = 1$}
      \label{fig:grho:small}  
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=\linewidth]{../plots/grho_large.pdf}       
      \caption{With $s = 5$}
      \label{fig:grho:large}
    \end{subfigure}
    \caption{Contour plot of $G_\rho - \rho$}
    \label{fig:grho}
  \end{figure}

\subsection[Derivatives of map]{Derivatives of $G$}

\begin{equation}
    \frac{\partial G_f}{\partial f} = \big(1 - G_f\big) \ \frac{1 - \rho}{\rho} \left(
        \psi ^{(0)}\left((1 - f)\frac{1- \rho}{\rho} + s\right) -
        \psi ^{(0)}\left((1 - f)\frac{1- \rho}{\rho}\right)\right)
\end{equation}

\begin{equation}
    \begin{split}
        \frac{\partial G_f}{\partial \rho} = \frac{1 - G_f}{\rho^2} \Bigg[ (1-f)&\left[
            \psi ^{(0)}\left((1 - f)\frac{1- \rho}{\rho} + s\right) -
            \psi ^{(0)}\left((1 - f)\frac{1- \rho}{\rho}\right)\right] - \\
            &\left[
                \psi ^{(0)}\left(\frac{1- \rho}{\rho} + s\right) -
                \psi ^{(0)}\left(\frac{1- \rho}{\rho}\right)\right]
            \Bigg]
    \end{split}
\end{equation}

% --- Bibliography
\newpage
\printbibliography

\end{document}